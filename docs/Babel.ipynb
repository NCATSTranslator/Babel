{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Babel",
   "id": "96f21e77167657c0"
  },
  {
   "cell_type": "code",
   "id": "9a18b461-6c0e-43fa-bf28-68dc8720adf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T22:50:41.119988Z",
     "start_time": "2026-01-22T22:50:41.082382Z"
    }
   },
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "os.chdir(\"..\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "79ee7d5c-f1da-4a19-985f-2ea00e1c0361",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-01-22T22:50:52.879616Z"
    }
   },
   "source": [
    "# The number of CPU cores to use. You can run `nproc` to find out how many cores you have.\n",
    "CORES=5\n",
    "\n",
    "subprocess.run([\"uv\", \"run\", \"snakemake\", \"-c\", str(CORES), \"macromolecular_complex\"])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assuming unrestricted shared filesystem usage.\n",
      "INFO snakemake.logging [2026-01-22T22:50:58-0500]: Assuming unrestricted shared filesystem usage.\n",
      "INFO snakemake.logging [2026-01-22T22:50:58-0500]: None\n",
      "host: RENCI_C6YQQ7H9L4\n",
      "INFO snakemake.logging [2026-01-22T22:50:58-0500]: host: RENCI_C6YQQ7H9L4\n",
      "Building DAG of jobs...\n",
      "INFO snakemake.logging [2026-01-22T22:50:58-0500]: Building DAG of jobs...\n",
      "Using shell: /opt/homebrew/bin/bash\n",
      "INFO snakemake.logging [2026-01-22T22:50:58-0500]: Using shell: /opt/homebrew/bin/bash\n",
      "Provided cores: 5\n",
      "INFO snakemake.logging [2026-01-22T22:50:58-0500]: Provided cores: 5\n",
      "Rules claiming more threads will be scaled down.\n",
      "INFO snakemake.logging [2026-01-22T22:50:58-0500]: Rules claiming more threads will be scaled down.\n",
      "Job stats:\n",
      "job                                          count\n",
      "-----------------------------------------  -------\n",
      "check_macromolecular_complex                     1\n",
      "check_macromolecular_complex_completeness        1\n",
      "get_icrdf                                        1\n",
      "get_obo_synonyms                                 1\n",
      "macromolecular_complex                           1\n",
      "macromolecular_complex_compendia                 1\n",
      "total                                            6\n",
      "\n",
      "INFO snakemake.logging [2026-01-22T22:50:58-0500]: Job stats:\n",
      "job                                          count\n",
      "-----------------------------------------  -------\n",
      "check_macromolecular_complex                     1\n",
      "check_macromolecular_complex_completeness        1\n",
      "get_icrdf                                        1\n",
      "get_obo_synonyms                                 1\n",
      "macromolecular_complex                           1\n",
      "macromolecular_complex_compendia                 1\n",
      "total                                            6\n",
      "\n",
      "Select jobs to execute...\n",
      "INFO snakemake.logging [2026-01-22T22:50:58-0500]: Select jobs to execute...\n",
      "Execute 1 jobs...\n",
      "INFO snakemake.logging [2026-01-22T22:50:58-0500]: Execute 1 jobs...\n",
      "\n",
      "[Thu Jan 22 17:50:58 2026]\n",
      "localrule get_obo_synonyms:\n",
      "    output: babel_downloads/common/ubergraph/synonyms.jsonl, babel_downloads/GO/synonyms, babel_downloads/CL/synonyms, babel_downloads/NCIT/synonyms, babel_downloads/UBERON/synonyms, babel_downloads/CHEBI/synonyms, babel_downloads/HP/synonyms, babel_downloads/MONDO/synonyms, babel_downloads/PR/synonyms\n",
      "    jobid: 7\n",
      "    reason: Missing output files: babel_downloads/common/ubergraph/synonyms.jsonl\n",
      "    resources: tmpdir=/var/folders/d3/r4v2tl8507g1zjplc7mqwwv80000gq/T\n",
      "INFO snakemake.logging [2026-01-22T22:50:58-0500]:  Rule: get_obo_synonyms, Jobid: 7\n",
      "INFO snakemake.logging [2026-01-22T22:50:58-0500]: Shell command: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying get_all_synonyms() offset 0 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 200000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 400000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 600000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 800000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 1000000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 1200000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 1400000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 1600000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 1800000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 2000000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 2200000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 2400000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 2600000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 2800000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 3000000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 3200000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 3400000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 3600000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 3800000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 4000000 limit 200000 (total count: 4277825)\n",
      "Querying get_all_synonyms() offset 4200000 limit 200000 (total count: 4277825)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING root [2026-01-22T22:59:39-0500]: Prefix GO not found in UberGraph synonyms download.\n",
      "WARNING root [2026-01-22T22:59:39-0500]: Prefix CL not found in UberGraph synonyms download.\n",
      "WARNING root [2026-01-22T22:59:39-0500]: Prefix NCIT not found in UberGraph synonyms download.\n",
      "WARNING root [2026-01-22T22:59:39-0500]: Prefix UBERON not found in UberGraph synonyms download.\n",
      "WARNING root [2026-01-22T22:59:39-0500]: Prefix CHEBI not found in UberGraph synonyms download.\n",
      "WARNING root [2026-01-22T22:59:39-0500]: Prefix HP not found in UberGraph synonyms download.\n",
      "WARNING root [2026-01-22T22:59:39-0500]: Prefix MONDO not found in UberGraph synonyms download.\n",
      "WARNING root [2026-01-22T22:59:39-0500]: Prefix PR not found in UberGraph synonyms download.\n",
      "[Thu Jan 22 17:59:39 2026]\n",
      "Finished jobid: 7 (Rule: get_obo_synonyms)\n",
      "INFO snakemake.logging [2026-01-22T22:59:39-0500]: Finished jobid: 7 (Rule: get_obo_synonyms)\n",
      "1 of 6 steps (17%) done\n",
      "INFO snakemake.logging [2026-01-22T22:59:39-0500]: None\n",
      "Select jobs to execute...\n",
      "INFO snakemake.logging [2026-01-22T22:59:39-0500]: Select jobs to execute...\n",
      "Execute 1 jobs...\n",
      "INFO snakemake.logging [2026-01-22T22:59:39-0500]: Execute 1 jobs...\n",
      "\n",
      "[Thu Jan 22 17:59:39 2026]\n",
      "localrule get_icrdf:\n",
      "    input: babel_downloads/common/ubergraph/labels, babel_downloads/common/ubergraph/synonyms.jsonl, babel_downloads/common/ubergraph/descriptions.jsonl\n",
      "    output: babel_downloads/icRDF.tsv\n",
      "    jobid: 5\n",
      "    reason: Missing output files: babel_downloads/icRDF.tsv; Input files updated by another job: babel_downloads/common/ubergraph/synonyms.jsonl\n",
      "    resources: tmpdir=/var/folders/d3/r4v2tl8507g1zjplc7mqwwv80000gq/T\n",
      "INFO snakemake.logging [2026-01-22T22:59:39-0500]:  Rule: get_icrdf, Jobid: 5\n",
      "INFO snakemake.logging [2026-01-22T22:59:39-0500]: Shell command: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying write_normalized_information_content() offset 0 limit 200000 (total count: 3885076)\n",
      "Querying write_normalized_information_content() offset 200000 limit 200000 (total count: 3885076)\n",
      "Querying write_normalized_information_content() offset 400000 limit 200000 (total count: 3885076)\n",
      "Querying write_normalized_information_content() offset 600000 limit 200000 (total count: 3885076)\n",
      "Querying write_normalized_information_content() offset 800000 limit 200000 (total count: 3885076)\n",
      "Querying write_normalized_information_content() offset 1000000 limit 200000 (total count: 3885076)\n",
      "Querying write_normalized_information_content() offset 1200000 limit 200000 (total count: 3885076)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f1dad66bad69c9d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
