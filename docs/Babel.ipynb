{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f21e77167657c0",
   "metadata": {},
   "source": [
    "# Babel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13384de2-1c99-4aa6-8792-de8ba393589e",
   "metadata": {},
   "source": [
    "This Jupyter Notebook shows you what it looks like when you [run Babel](https://github.com/NCATSTranslator/Babel/blob/master/docs/Downloads.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b75a9-d6e4-4c96-b0c3-42d20b27ec7f",
   "metadata": {},
   "source": [
    "First, let's make sure that we're in the right directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a18b461-6c0e-43fa-bf28-68dc8720adf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T22:50:41.119988Z",
     "start_time": "2026-01-22T22:50:41.082382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are in the Babel Git repository!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Make sure we're in the root directory of the Babel Git repository.\n",
    "cwd = Path.cwd()\n",
    "possible_directories = [\n",
    "    # Try CWD\n",
    "    cwd,\n",
    "    # Try parent\n",
    "    cwd.parent\n",
    "]\n",
    "found = False\n",
    "for directory in possible_directories:\n",
    "    if (directory / \"Snakefile\").exists() and (directory / \".git\").is_dir():\n",
    "        found = True\n",
    "        \n",
    "        # Found it!\n",
    "        if directory == cwd:\n",
    "            print(f\"We are in the Babel Git repository!\")\n",
    "        else:\n",
    "            print(f\"Found the Babel Git repository at {directory}, changing to that directory.\")\n",
    "            os.chdir(directory)\n",
    "\n",
    "if not found:\n",
    "    raise RuntimeError(f\"Could not find Babel Git repository in one of these locations: {possible_directories}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee7d5c-f1da-4a19-985f-2ea00e1c0361",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-01-22T22:50:52.879616Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assuming unrestricted shared filesystem usage.\n",
      "INFO snakemake.logging [2026-01-27T06:37:32-0500]: Assuming unrestricted shared filesystem usage.\n",
      "INFO snakemake.logging [2026-01-27T06:37:32-0500]: None\n",
      "host: Vespasian.local\n",
      "INFO snakemake.logging [2026-01-27T06:37:32-0500]: host: Vespasian.local\n",
      "Building DAG of jobs...\n",
      "INFO snakemake.logging [2026-01-27T06:37:32-0500]: Building DAG of jobs...\n",
      "Using shell: /bin/bash\n",
      "INFO snakemake.logging [2026-01-27T06:37:32-0500]: Using shell: /bin/bash\n",
      "Provided cores: 5\n",
      "INFO snakemake.logging [2026-01-27T06:37:32-0500]: Provided cores: 5\n",
      "Rules claiming more threads will be scaled down.\n",
      "INFO snakemake.logging [2026-01-27T06:37:32-0500]: Rules claiming more threads will be scaled down.\n",
      "Job stats:\n",
      "job                                          count\n",
      "-----------------------------------------  -------\n",
      "check_macromolecular_complex                     1\n",
      "check_macromolecular_complex_completeness        1\n",
      "get_complexportal                                1\n",
      "get_complexportal_labels_and_synonyms            1\n",
      "get_icrdf                                        1\n",
      "get_obo_descriptions                             1\n",
      "get_obo_labels                                   1\n",
      "get_obo_synonyms                                 1\n",
      "macromolecular_complex                           1\n",
      "macromolecular_complex_compendia                 1\n",
      "macromolecular_complex_ids                       1\n",
      "total                                           11\n",
      "\n",
      "INFO snakemake.logging [2026-01-27T06:37:32-0500]: Job stats:\n",
      "job                                          count\n",
      "-----------------------------------------  -------\n",
      "check_macromolecular_complex                     1\n",
      "check_macromolecular_complex_completeness        1\n",
      "get_complexportal                                1\n",
      "get_complexportal_labels_and_synonyms            1\n",
      "get_icrdf                                        1\n",
      "get_obo_descriptions                             1\n",
      "get_obo_labels                                   1\n",
      "get_obo_synonyms                                 1\n",
      "macromolecular_complex                           1\n",
      "macromolecular_complex_compendia                 1\n",
      "macromolecular_complex_ids                       1\n",
      "total                                           11\n",
      "\n",
      "Select jobs to execute...\n",
      "INFO snakemake.logging [2026-01-27T06:37:32-0500]: Select jobs to execute...\n",
      "Execute 4 jobs...\n",
      "INFO snakemake.logging [2026-01-27T06:37:34-0500]: Execute 4 jobs...\n",
      "\n",
      "[Tue Jan 27 01:37:34 2026]\n",
      "localrule get_complexportal:\n",
      "    output: babel_downloads/ComplexPortal/559292.tsv\n",
      "    jobid: 3\n",
      "    reason: Missing output files: babel_downloads/ComplexPortal/559292.tsv\n",
      "    resources: tmpdir=/var/folders/g6/rc4zrl3n4j53nklxtnfpzpb40000gn/T\n",
      "INFO snakemake.logging [2026-01-27T06:37:34-0500]:  Rule: get_complexportal, Jobid: 3\n",
      "INFO snakemake.logging [2026-01-27T06:37:34-0500]: Shell command: None\n",
      "[Tue Jan 27 01:37:34 2026]\n",
      "localrule get_obo_descriptions:\n",
      "    output: babel_downloads/common/ubergraph/descriptions.jsonl\n",
      "    jobid: 8\n",
      "    reason: Missing output files: babel_downloads/common/ubergraph/descriptions.jsonl\n",
      "    resources: tmpdir=/var/folders/g6/rc4zrl3n4j53nklxtnfpzpb40000gn/T\n",
      "INFO snakemake.logging [2026-01-27T06:37:34-0500]:  Rule: get_obo_descriptions, Jobid: 8\n",
      "INFO snakemake.logging [2026-01-27T06:37:34-0500]: Shell command: None\n",
      "[Tue Jan 27 01:37:34 2026]\n",
      "localrule get_obo_labels:\n",
      "    output: babel_downloads/common/ubergraph/labels, babel_downloads/GO/labels, babel_downloads/CL/labels, babel_downloads/NCIT/labels, babel_downloads/UBERON/labels, babel_downloads/CHEBI/labels, babel_downloads/HP/labels, babel_downloads/MONDO/labels, babel_downloads/PR/labels\n",
      "    jobid: 6\n",
      "    reason: Missing output files: babel_downloads/common/ubergraph/labels\n",
      "    resources: tmpdir=/var/folders/g6/rc4zrl3n4j53nklxtnfpzpb40000gn/T\n",
      "INFO snakemake.logging [2026-01-27T06:37:34-0500]:  Rule: get_obo_labels, Jobid: 6\n",
      "INFO snakemake.logging [2026-01-27T06:37:34-0500]: Shell command: None\n",
      "[Tue Jan 27 01:37:34 2026]\n",
      "localrule get_obo_synonyms:\n",
      "    output: babel_downloads/common/ubergraph/synonyms.jsonl, babel_downloads/GO/synonyms, babel_downloads/CL/synonyms, babel_downloads/NCIT/synonyms, babel_downloads/UBERON/synonyms, babel_downloads/CHEBI/synonyms, babel_downloads/HP/synonyms, babel_downloads/MONDO/synonyms, babel_downloads/PR/synonyms\n",
      "    jobid: 7\n",
      "    reason: Missing output files: babel_downloads/common/ubergraph/synonyms.jsonl\n",
      "    resources: tmpdir=/var/folders/g6/rc4zrl3n4j53nklxtnfpzpb40000gn/T\n",
      "INFO snakemake.logging [2026-01-27T06:37:34-0500]:  Rule: get_obo_synonyms, Jobid: 7\n",
      "INFO snakemake.logging [2026-01-27T06:37:34-0500]: Shell command: None\n",
      "INFO src.babel_utils [2026-01-27T06:37:35-0500]: Downloading http://ftp.ebi.ac.uk/pub/databases/intact/complex/current/complextab/559292.tsv\n",
      "INFO src.babel_utils [2026-01-27T06:37:35-0500]: Downloading babel_downloads/ComplexPortal/559292.tsv using urllib, attempt 1...\n",
      "[Tue Jan 27 01:37:36 2026]\n",
      "Finished jobid: 3 (Rule: get_complexportal)\n",
      "INFO snakemake.logging [2026-01-27T06:37:36-0500]: Finished jobid: 3 (Rule: get_complexportal)\n",
      "1 of 11 steps (9%) done\n",
      "INFO snakemake.logging [2026-01-27T06:37:36-0500]: None\n",
      "Select jobs to execute...\n",
      "INFO snakemake.logging [2026-01-27T06:37:36-0500]: Select jobs to execute...\n",
      "Execute 1 jobs...\n",
      "INFO snakemake.logging [2026-01-27T06:37:36-0500]: Execute 1 jobs...\n",
      "\n",
      "[Tue Jan 27 01:37:36 2026]\n",
      "localrule get_complexportal_labels_and_synonyms:\n",
      "    input: babel_downloads/ComplexPortal/559292.tsv\n",
      "    output: babel_downloads/ComplexPortal/559292_labels.tsv, babel_downloads/ComplexPortal/559292_synonyms.tsv, babel_downloads/ComplexPortal/metadata.yaml\n",
      "    jobid: 2\n",
      "    reason: Missing output files: babel_downloads/ComplexPortal/559292_labels.tsv, babel_downloads/ComplexPortal/559292_synonyms.tsv, babel_downloads/ComplexPortal/metadata.yaml; Input files updated by another job: babel_downloads/ComplexPortal/559292.tsv\n",
      "    resources: tmpdir=/var/folders/g6/rc4zrl3n4j53nklxtnfpzpb40000gn/T\n",
      "INFO snakemake.logging [2026-01-27T06:37:36-0500]:  Rule: get_complexportal_labels_and_synonyms, Jobid: 2\n",
      "INFO snakemake.logging [2026-01-27T06:37:36-0500]: Shell command: None\n",
      "[Tue Jan 27 01:37:38 2026]\n",
      "Finished jobid: 2 (Rule: get_complexportal_labels_and_synonyms)\n",
      "INFO snakemake.logging [2026-01-27T06:37:38-0500]: Finished jobid: 2 (Rule: get_complexportal_labels_and_synonyms)\n",
      "2 of 11 steps (18%) done\n",
      "INFO snakemake.logging [2026-01-27T06:37:38-0500]: None\n",
      "Select jobs to execute...\n",
      "INFO snakemake.logging [2026-01-27T06:37:38-0500]: Select jobs to execute...\n",
      "Execute 1 jobs...\n",
      "INFO snakemake.logging [2026-01-27T06:37:38-0500]: Execute 1 jobs...\n",
      "\n",
      "[Tue Jan 27 01:37:38 2026]\n",
      "localrule macromolecular_complex_ids:\n",
      "    input: babel_downloads/ComplexPortal/559292_labels.tsv\n",
      "    output: babel_outputs/intermediate/macromolecular_complex/ids/ComplexPortal\n",
      "    jobid: 4\n",
      "    reason: Missing output files: babel_outputs/intermediate/macromolecular_complex/ids/ComplexPortal; Input files updated by another job: babel_downloads/ComplexPortal/559292_labels.tsv\n",
      "    resources: tmpdir=/var/folders/g6/rc4zrl3n4j53nklxtnfpzpb40000gn/T\n",
      "INFO snakemake.logging [2026-01-27T06:37:38-0500]:  Rule: macromolecular_complex_ids, Jobid: 4\n",
      "INFO snakemake.logging [2026-01-27T06:37:38-0500]: Shell command: awk '{print $1\"\tbiolink:MacromolecularComplex\"}' babel_downloads/ComplexPortal/559292_labels.tsv > babel_outputs/intermediate/macromolecular_complex/ids/ComplexPortal\n",
      "[Tue Jan 27 01:37:38 2026]\n",
      "Finished jobid: 4 (Rule: macromolecular_complex_ids)\n",
      "INFO snakemake.logging [2026-01-27T06:37:38-0500]: Finished jobid: 4 (Rule: macromolecular_complex_ids)\n",
      "3 of 11 steps (27%) done\n",
      "INFO snakemake.logging [2026-01-27T06:37:38-0500]: None\n",
      "INFO src.ubergraph [2026-01-27T06:37:44-0500]: Querying get_all_synonyms() offset 0 limit 200000 (total count: 4277825)\n",
      "INFO src.ubergraph [2026-01-27T06:37:46-0500]: Querying get_all_descriptions() offset 0 limit 200000 (total count: 3819000)\n",
      "INFO src.ubergraph [2026-01-27T06:37:46-0500]: Querying get_all_labels() offset 0 limit 200000 (total count: 3819000)\n",
      "INFO src.ubergraph [2026-01-27T06:38:01-0500]: Querying get_all_synonyms() offset 200000 limit 200000 (total count: 4277825)\n",
      "INFO src.ubergraph [2026-01-27T06:38:03-0500]: Querying get_all_descriptions() offset 200000 limit 200000 (total count: 3819000)\n",
      "INFO src.ubergraph [2026-01-27T06:38:06-0500]: Querying get_all_labels() offset 200000 limit 200000 (total count: 3819000)\n",
      "INFO src.ubergraph [2026-01-27T06:38:16-0500]: Querying get_all_descriptions() offset 400000 limit 200000 (total count: 3819000)\n",
      "INFO src.ubergraph [2026-01-27T06:38:17-0500]: Querying get_all_synonyms() offset 400000 limit 200000 (total count: 4277825)\n",
      "INFO src.ubergraph [2026-01-27T06:38:21-0500]: Querying get_all_labels() offset 400000 limit 200000 (total count: 3819000)\n",
      "INFO src.ubergraph [2026-01-27T06:38:33-0500]: Querying get_all_descriptions() offset 600000 limit 200000 (total count: 3819000)\n",
      "WARNING src.ubergraph [2026-01-27T06:38:41-0500]: Unable to translate http://purl.obolibrary.org/obo/so#contains to a CURIE; it will be used as-is: Unable to opt_to_curie(http://purl.obolibrary.org/obo/so#contains): output calculated as so#contains, which has no colon.\n",
      "WARNING src.ubergraph [2026-01-27T06:38:41-0500]: Unable to translate http://purl.obolibrary.org/obo/so#finishes to a CURIE; it will be used as-is: Unable to opt_to_curie(http://purl.obolibrary.org/obo/so#finishes): output calculated as so#finishes, which has no colon.\n",
      "WARNING src.ubergraph [2026-01-27T06:38:41-0500]: Unable to translate http://purl.obolibrary.org/obo/so#gained to a CURIE; it will be used as-is: Unable to opt_to_curie(http://purl.obolibrary.org/obo/so#gained): output calculated as so#gained, which has no colon.\n",
      "WARNING src.ubergraph [2026-01-27T06:38:41-0500]: Unable to translate http://purl.obolibrary.org/obo/so#lost to a CURIE; it will be used as-is: Unable to opt_to_curie(http://purl.obolibrary.org/obo/so#lost): output calculated as so#lost, which has no colon.\n",
      "WARNING src.ubergraph [2026-01-27T06:38:41-0500]: Unable to translate http://purl.obolibrary.org/obo/so#overlaps to a CURIE; it will be used as-is: Unable to opt_to_curie(http://purl.obolibrary.org/obo/so#overlaps): output calculated as so#overlaps, which has no colon.\n",
      "WARNING src.ubergraph [2026-01-27T06:38:41-0500]: Unable to translate http://purl.obolibrary.org/obo/so#starts to a CURIE; it will be used as-is: Unable to opt_to_curie(http://purl.obolibrary.org/obo/so#starts): output calculated as so#starts, which has no colon.\n",
      "INFO src.ubergraph [2026-01-27T06:38:46-0500]: Querying get_all_descriptions() offset 800000 limit 200000 (total count: 3819000)\n",
      "INFO src.ubergraph [2026-01-27T06:38:53-0500]: Querying get_all_descriptions() offset 1000000 limit 200000 (total count: 3819000)\n",
      "INFO src.ubergraph [2026-01-27T06:38:58-0500]: Querying get_all_labels() offset 600000 limit 200000 (total count: 3819000)\n",
      "INFO src.ubergraph [2026-01-27T06:39:00-0500]: Querying get_all_descriptions() offset 1200000 limit 200000 (total count: 3819000)\n",
      "INFO src.ubergraph [2026-01-27T06:39:01-0500]: Querying get_all_synonyms() offset 600000 limit 200000 (total count: 4277825)\n",
      "INFO src.ubergraph [2026-01-27T06:39:08-0500]: Querying get_all_descriptions() offset 1400000 limit 200000 (total count: 3819000)\n",
      "INFO src.ubergraph [2026-01-27T06:39:15-0500]: Querying get_all_descriptions() offset 1600000 limit 200000 (total count: 3819000)\n"
     ]
    }
   ],
   "source": [
    "# The number of CPU cores to use. You can run `nproc` to find out how many cores you have.\n",
    "CORES=5\n",
    "\n",
    "# Run the macromolecular complex Babel pipeline.\n",
    "subprocess.run([\"uv\", \"run\", \"snakemake\", \"-c\", str(CORES), \"macromolecular_complex\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
