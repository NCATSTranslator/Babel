#!/bin/bash -l
#SBATCH --job-name=babel-test-cluster
#SBATCH --output=babel-test-cluster.out
#SBATCH --time=1:00:00
#SBATCH --mem=2G
#SBATCH -n 1

source ~/.bashrc
conda activate babel

# Go to Babel project directory
cd /projects/babel/babel-ht-test/Babel

export UMLS_API_KEY="YOUR UMLS API KEY"
export PYTHONPATH=.

# Build anatomy related compendia in a distributed fashion as defined in slurm/config.yaml profile 
# Note that since Snakemake supports slurm executor plugin natively, submitting this as a SLURM batch 
# job is not recommended since that will create an outer SLURM job running Snakemake which then 
# submits innter SLURM jobs for workflow rules as specified in the profile. The recommended way 
# is to run this directly on the login or head node. However, it might not be a good thing to have 
# a long-running process on login/head nodes. So a good compromise is to still use the sbatch wrapper 
# to submit the snakemake job but request minimal resources for the outer job as shown in this job script.
snakemake --profile slurm anatomy
